{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegCaps on Image Segmentation for Person\n",
    "## Integrated with WebCam Video\n",
    "\n",
    "A quick intro to using the pre-trained model to detect and segment object of person.\n",
    "\n",
    "This notebook tests the model loading function from image file of a saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from os.path import join, basename\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import SimpleITK as sitk\n",
    "import numpy as np\n",
    "# import skimage.io\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Add the ptdraft folder path to the sys.path list\n",
    "sys.path.append('../')\n",
    "\n",
    "from keras.utils import print_summary\n",
    "from keras import layers, models\n",
    "\n",
    "import segcapsnet.capsnet as modellib\n",
    "import models.unet as unet\n",
    "\n",
    "from utils.model_helper import create_model\n",
    "from utils.load_2D_data import generate_test_batches, generate_test_image\n",
    "from test import *\n",
    "from PIL import Image\n",
    "import scipy.ndimage.morphology\n",
    "from skimage import measure, filters\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "RESOLUTION = 512\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = path.dirname(\"../\")\n",
    "DATA_DIR = path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "# MODEL_DIR = path.join(DATA_DIR, \"saved_models/segcapsr3/m1.hdf5\") # LUNA16\n",
    "\n",
    "# Local path to trained weights file\n",
    "# loss function = Dice is better than BCE (Binary Cross Entropy)\n",
    "# COCO_MODEL_PATH = path.join(DATA_DIR, \"saved_models/segcapsr3/dice16-255.hdf5\") # MSCOCO17\n",
    "# COCO_MODEL_PATH = path.join(DATA_DIR, \"saved_models/capsbasic/mcb11-r0.1.hdf5\") # MSCOCO17\n",
    "# COCO_MODEL_PATH = path.join(DATA_DIR, \"saved_models/segcapsr3/mar10-255.hdf5\") # MSCOCO17\n",
    "# COCO_MODEL_PATH = path.join(DATA_DIR, \"saved_models/segcapsr3/bce.hdf5\") # MSCOCO17\n",
    "COCO_MODEL_PATH = path.join(DATA_DIR, \"saved_models/unet/split-0_batch-1_shuff-1_aug-1_loss-w_bce_slic-1_sub--1_strid-1_lr-0.0001_recon-131.072_model_20180629-084919.hdf5\") # MSCOCO17\n",
    "\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = path.join(DATA_DIR, \"imgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 512, 512, 64) 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 256, 256, 64) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 128 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 128 147584      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 256 295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 256 590080      conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 512)  1180160     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 512)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 1024) 4719616     max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 1024) 9438208     conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 512)  2097664     conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 1024) 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 256 524544      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 256 590080      conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 128 131200      conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 128 295040      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 128 147584      conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 512, 512, 64) 32832       conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 512, 512, 1)  65          conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,030,593\n",
      "Trainable params: 31,030,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model object in inference mode.\n",
    "net_input_shape = (RESOLUTION, RESOLUTION, 1)\n",
    "num_class = 2\n",
    "# train_model, eval_model, manipulate_model = modellib.CapsNetR3(net_input_shape, num_class)\n",
    "# train_model, eval_model, manipulate_model = modellib.CapsNetBasic(net_input_shape, num_class)\n",
    "eval_model = unet.UNet(net_input_shape)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "eval_model.load_weights(COCO_MODEL_PATH)\n",
    "print_summary(model=eval_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def threshold_mask(raw_output, threshold):\n",
    "    if threshold == 0:\n",
    "        try:\n",
    "            threshold = filters.threshold_otsu(raw_output)\n",
    "        except:\n",
    "            threshold = 0.5\n",
    "\n",
    "    print('\\tThreshold: {}'.format(threshold))\n",
    "\n",
    "    raw_output[raw_output > threshold] = 1\n",
    "    raw_output[raw_output < 1] = 0\n",
    "\n",
    "    all_labels = measure.label(raw_output)\n",
    "    props = measure.regionprops(all_labels)\n",
    "    props.sort(key=lambda x: x.area, reverse=True)\n",
    "    thresholded_mask = np.zeros(raw_output.shape)\n",
    "\n",
    "    if len(props) >= 2:\n",
    "        if props[0].area / props[1].area > 5:  # if the largest is way larger than the second largest\n",
    "            thresholded_mask[all_labels == props[0].label] = 1  # only turn on the largest component\n",
    "        else:\n",
    "            thresholded_mask[all_labels == props[0].label] = 1  # turn on two largest components\n",
    "            thresholded_mask[all_labels == props[1].label] = 1\n",
    "    elif len(props):\n",
    "        thresholded_mask[all_labels == props[0].label] = 1\n",
    "\n",
    "    thresholded_mask = scipy.ndimage.morphology.binary_fill_holes(thresholded_mask).astype(np.uint8)\n",
    "\n",
    "    return thresholded_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Segmentation of Person\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-29 08:11:40.049080\n",
      "1/1 [==============================] - 13s 13s/step\n",
      "2018-06-29 08:11:53.493833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = ['train2.png']\n",
    "output_array = None\n",
    "\n",
    "\n",
    "# sitk_img = sitk.ReadImage(join(IMAGE_DIR, img[0]))\n",
    "# img_data = sitk.GetArrayFromImage(sitk_img)\n",
    "img_data = np.asarray(Image.open(join(IMAGE_DIR, img[0])))\n",
    "\n",
    "    \n",
    "print(str(datetime.now()))\n",
    "output_array = eval_model.predict_generator(generate_test_batches(DATA_DIR, [img],\n",
    "                                                                  net_input_shape,\n",
    "                                                                  batchSize=1,\n",
    "                                                                  numSlices=1,\n",
    "                                                                  subSampAmt=0,\n",
    "                                                                  stride=1),\n",
    "                                            steps=1, max_queue_size=1, workers=1,\n",
    "                                            use_multiprocessing=False, verbose=1)\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_array contain 2 masks in a list, show the first element.\n",
    "# print('len(output_array)=%d'%(len(output_array)))\n",
    "# print('test.test: output_array=%s'%(output_array[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.test: output=[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# output = (1, 512, 512)\n",
    "# output = output_array[0][:,:,:,0] # A list with two images, get first one image and reshape it to 3 dimensions.\n",
    "# recon = output_array[1][:,:,:,0]\n",
    "\n",
    "# For unet\n",
    "output = output_array[:,:,:,0]\n",
    "# image store in tuple structure.\n",
    "print('test.test: output=%s'%(output))\n",
    "np.ndim(output)\n",
    "np_output = np.array(output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting Output\n",
      "\tThreshold: 0.5\n"
     ]
    }
   ],
   "source": [
    "# output_img = sitk.GetImageFromArray(output[0,:,:], isVector=True)\n",
    "\n",
    "print('Segmenting Output')\n",
    "threshold_level = 0\n",
    "output_bin = threshold_mask(output, threshold_level)\n",
    "# output2d = output[0,:,:]\n",
    "# output2d = recon[0,:,:]\n",
    "# print(output2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221cc330d68>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22180249358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(output[0,:,:], cmap='gray')\n",
    "# plt.imsave('raw_output' + img[0][-4:], output[0,:,:])\n",
    "plt.imshow(output_bin[0,:,:], cmap='gray')\n",
    "# plt.imsave('final_output' + img[0][-4:], output_bin[0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mask = output2d[...] > threshold_level\n",
    "\n",
    "\n",
    "# Set all masked pixels to zero\n",
    "# masked = img_data.copy()\n",
    "# masked[mask] = 0\n",
    "# # print(masked)\n",
    "# # output_mask = sitk.GetImageFromArray(output_bin[0,:,:], isVector=True)\n",
    "# #     output_img = np.reshape(output_img, [512, 512, 1])\n",
    "# #     output_mask = np.reshape(output_mask, [512, 512, 1])\n",
    "\n",
    "# Display original and masked images side-by-side\n",
    "# print('threshold_level=%f'%threshold_level)\n",
    "# plt.figure()\n",
    "# f, (ax0, ax1) = plt.subplots(1, 2)\n",
    "\n",
    "# ax0.imshow(img_data)\n",
    "# ax1.imshow(masked)\n",
    "# plt.axis('off')\n",
    "\n",
    "\n",
    "# cv2.imshow(\"Masked\",masked)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c28a973d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output2d, cmap=plt.cm.Greys_r)\n",
    "plt.axis('off');\n",
    "# plt.imsave('./output_img.png', output2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate with Video Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import cv2\n",
    "import colorsys\n",
    "from IPython import display\n",
    "import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition for FPS calculation and webcam threading.\n",
    "\n",
    "#### Reference\n",
    "1. Adrian Rosebrock, imutils, https://github.com/jrosebr1/imutils/tree/master/imutils/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPS:\n",
    "    def __init__(self):\n",
    "        # store the start time, end time, and total number of frames\n",
    "        # that were examined between the start and end intervals\n",
    "        self._start = None\n",
    "        self._end = None\n",
    "        self._numFrames = 0\n",
    "\n",
    "    def start(self):\n",
    "        # start the timer\n",
    "        self._start = datetime.now()\n",
    "        return self\n",
    "\n",
    "    def stop(self):\n",
    "        # stop the timer\n",
    "        self._end = datetime.now()\n",
    "\n",
    "    def update(self):\n",
    "        # increment the total number of frames examined during the\n",
    "        # start and end intervals\n",
    "        self._numFrames += 1\n",
    "\n",
    "    def elapsed(self):\n",
    "        # return the total number of seconds between the start and\n",
    "        # end interval\n",
    "        return (self._end - self._start).total_seconds()\n",
    "\n",
    "    def fps(self):\n",
    "        # compute the (approximate) frames per second\n",
    "        return self._numFrames / self.elapsed()\n",
    "\n",
    "class WebcamVideoStream:\n",
    "    def __init__(self, src=0, name=\"WebcamVideoStream\"):\n",
    "        # initialize the video camera stream and read the first frame\n",
    "        # from the stream\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "        # initialize the thread name\n",
    "        self.name = name\n",
    "        \n",
    "        # initialize the variable used to indicate if the thread should\n",
    "        # be stopped\n",
    "        self.stopped = False\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "        # start the thread to read frames from the video stream\n",
    "        t = Thread(target=self.update, name=self.name, args=())\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "        return self\n",
    "    \n",
    "    def update(self):\n",
    "        # keep looping infinitely until the thread is stopped\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "            # otherwise, read the next frame from the stream\n",
    "            (self.grabbed, self.frame) = self.stream.read()           \n",
    "            \n",
    "    def read(self):\n",
    "        # return the frame most recently read\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        self.stopped = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Major display function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_colors(N):\n",
    "    np.random.seed(70)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.4):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "\n",
    "        image = apply_mask(image, mask, color)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        image = cv2.putText(\n",
    "            image, caption, (x1+2, y1-7), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a signal function to capture the interruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_handler(signal, frame):\n",
    "    # KeyboardInterrupt detected, exiting\n",
    "    global is_interrupted\n",
    "    is_interrupted = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model (model_path, net_input_shape, num_class):\n",
    "    train_model, eval_model, manipulate_model = modellib.CapsNetR3(net_input_shape, num_class)\n",
    "\n",
    "    # Load weights trained on MS-COCO\n",
    "    eval_model.load_weights(model_path)\n",
    "\n",
    "    class_names = ['person']\n",
    "    return class_names, eval_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interrupt the kernel to stop the capture or wait for 50 frames processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sampling THREADED frames from webcam...\n",
      "1/1 [==============================] - 83s 83s/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-44f508449a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         frame = display_instances(\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rois'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'masks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         )\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# check to see if the frame should be displayed to our screen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    net_input_shape = (RESOLUTION, RESOLUTION, 1)\n",
    "    num_class = 2    \n",
    "    class_names, model = get_model(COCO_MODEL_PATH, net_input_shape, num_class)\n",
    "\n",
    "    # created a *threaded* video stream, allow the camera sensor to warmup,\n",
    "    # and start the FPS counter\n",
    "    print(\"[INFO] sampling THREADED frames from webcam...\")\n",
    "    vs = WebcamVideoStream(src=0).start()\n",
    "    fps = FPS().start()\n",
    "    frame = vs.read()\n",
    "    \n",
    "    signal.signal(signal.SIGINT, signal_handler)\n",
    "    is_interrupted = False\n",
    "\n",
    "    # loop over 50 frames...this time using the threaded stream\n",
    "    while fps._numFrames < 50:\n",
    "        # grab the frame from the threaded video stream\n",
    "        frame = vs.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # check to see if the frame should be displayed to our screen\n",
    "        results = model.predict_generator(generate_test_image(\n",
    "                                        test_img=frame, net_input_shape=net_input_shape,\n",
    "                                        batchSize=1, numSlices=1,\n",
    "                                        subSampAmt=0, stride=1, downSampAmt=1),\n",
    "                                        steps=1, max_queue_size=1, workers=1,\n",
    "                                        use_multiprocessing=False, verbose=1)\n",
    "        \n",
    "        \n",
    "        r = results[0]\n",
    "        frame = display_instances(\n",
    "                frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
    "        )\n",
    "        # check to see if the frame should be displayed to our screen\n",
    "        \n",
    "        plt.imshow(frame)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        try:    # Avoids a NotImplementedError caused by `plt.pause`\n",
    "            plt.pause(5.05) # the pause time\n",
    "        except Exception:\n",
    "            pass\n",
    "        # update the FPS counter\n",
    "        fps.update()\n",
    "        if is_interrupted:\n",
    "            break\n",
    "    # stop the timer and display FPS information\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    " \n",
    "    # do a bit of cleanup\n",
    "    vs.stop()\n",
    "#     cv2.destroyAllWindows()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
