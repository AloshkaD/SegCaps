{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegCaps on Image Segmentation for Person\n",
    "\n",
    "A quick intro to using the pre-trained model to detect and segment object of person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "# import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Add the ptdraft folder path to the sys.path list\n",
    "sys.path.append('../')\n",
    "\n",
    "from keras.utils import print_summary\n",
    "\n",
    "import capsnet as modellib\n",
    "from data_helper import *\n",
    "from test import *\n",
    "from PIL import Image\n",
    "import scipy.ndimage.morphology\n",
    "from skimage import measure, filters\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "RESOLUTION = 512\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = path.dirname(\"../\")\n",
    "DATA_DIR = path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = path.join(DATA_DIR, \"saved_models/segcapsr3/m1.hdf5\") # LUNA16\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = path.join(DATA_DIR, \"saved_models/segcapsr3/m5c.hdf5\") # MSCOCO17\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = path.join(DATA_DIR, \"imgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ..\\capsule_layers.py:322: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From ..\\capsule_layers.py:351: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 512, 512, 16) 416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 512, 512, 1,  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycaps (ConvCapsuleLayer)  (None, 256, 256, 2,  12832       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_cap_2_1 (ConvCapsuleLayer) (None, 256, 256, 4,  25664       primarycaps[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_cap_2_2 (ConvCapsuleLayer) (None, 128, 128, 4,  51328       conv_cap_2_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_cap_3_1 (ConvCapsuleLayer) (None, 128, 128, 8,  205056      conv_cap_2_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_cap_3_2 (ConvCapsuleLayer) (None, 64, 64, 8, 64 410112      conv_cap_3_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_cap_4_1 (ConvCapsuleLayer) (None, 64, 64, 8, 32 409856      conv_cap_3_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "deconv_cap_1_1 (DeconvCapsuleLa (None, 128, 128, 8,  131328      conv_cap_4_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_1 (Concatenate)              (None, 128, 128, 16, 0           deconv_cap_1_1[0][0]             \n",
      "                                                                 conv_cap_3_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "deconv_cap_1_2 (ConvCapsuleLaye (None, 128, 128, 4,  102528      up_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "deconv_cap_2_1 (DeconvCapsuleLa (None, 256, 256, 4,  32832       deconv_cap_1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_2 (Concatenate)              (None, 256, 256, 8,  0           deconv_cap_2_1[0][0]             \n",
      "                                                                 conv_cap_2_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "deconv_cap_2_2 (ConvCapsuleLaye (None, 256, 256, 4,  25664       up_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "deconv_cap_3_1 (DeconvCapsuleLa (None, 512, 512, 2,  8224        deconv_cap_2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_3 (Concatenate)              (None, 512, 512, 3,  0           deconv_cap_3_1[0][0]             \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seg_caps (ConvCapsuleLayer)     (None, 512, 512, 1,  272         up_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "mask_2 (Mask)                   (None, 512, 512, 1,  0           seg_caps[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 512, 512, 16) 0           mask_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "recon_1 (Conv2D)                (None, 512, 512, 64) 1088        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "recon_2 (Conv2D)                (None, 512, 512, 128 8320        recon_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_seg (Length)                (None, 512, 512, 1)  0           seg_caps[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_recon (Conv2D)              (None, 512, 512, 1)  129         recon_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,425,649\n",
      "Trainable params: 1,425,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model object in inference mode.\n",
    "net_input_shape = (RESOLUTION, RESOLUTION, 1)\n",
    "num_class = 2\n",
    "train_model, eval_model, manipulate_model = modellib.CapsNetR3(net_input_shape, num_class)\n",
    "\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "eval_model.load_weights(COCO_MODEL_PATH)\n",
    "print_summary(model=eval_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def threshold_mask(raw_output, threshold):\n",
    "    if threshold == 0:\n",
    "        try:\n",
    "            threshold = filters.threshold_otsu(raw_output)\n",
    "        except:\n",
    "            threshold = 0.5\n",
    "\n",
    "    print('\\tThreshold: {}'.format(threshold))\n",
    "\n",
    "    raw_output[raw_output > threshold] = 1\n",
    "    raw_output[raw_output < 1] = 0\n",
    "\n",
    "    all_labels = measure.label(raw_output)\n",
    "    props = measure.regionprops(all_labels)\n",
    "    props.sort(key=lambda x: x.area, reverse=True)\n",
    "    thresholded_mask = np.zeros(raw_output.shape)\n",
    "\n",
    "    if len(props) >= 2:\n",
    "        if props[0].area / props[1].area > 5:  # if the largest is way larger than the second largest\n",
    "            thresholded_mask[all_labels == props[0].label] = 1  # only turn on the largest component\n",
    "        else:\n",
    "            thresholded_mask[all_labels == props[0].label] = 1  # turn on two largest components\n",
    "            thresholded_mask[all_labels == props[1].label] = 1\n",
    "    elif len(props):\n",
    "        thresholded_mask[all_labels == props[0].label] = 1\n",
    "\n",
    "    thresholded_mask = scipy.ndimage.morphology.binary_fill_holes(thresholded_mask).astype(np.uint8)\n",
    "\n",
    "    return thresholded_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Segmentation of Person\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-24 15:00:04.614745\n",
      "load_2D_data.generate_test_batches\n",
      "load_2D_data.generate_test_batches: test_list=[['train4.png']]\n",
      "1/1 [==============================] - 87s 87s/step\n",
      "2018-06-24 15:01:31.959672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = ['train4.png']\n",
    "output_array = None\n",
    "\n",
    "\n",
    "sitk_img = sitk.ReadImage(join(IMAGE_DIR, img[0]))\n",
    "img_data = sitk.GetArrayFromImage(sitk_img)\n",
    "    \n",
    "generate_test_batches = get_test_batches_generator('mscoco17')\n",
    "print(str(datetime.now()))\n",
    "output_array = eval_model.predict_generator(generate_test_batches(DATA_DIR, [img],\n",
    "                                                                  net_input_shape,\n",
    "                                                                  batchSize=1,\n",
    "                                                                  numSlices=1,\n",
    "                                                                  subSampAmt=0,\n",
    "                                                                  stride=1),\n",
    "                                            steps=1, max_queue_size=1, workers=1,\n",
    "                                            use_multiprocessing=False, verbose=1)\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_array contain 2 masks in a list, show the first element.\n",
    "# print('len(output_array)=%d'%(len(output_array)))\n",
    "# print('test.test: output_array=%s'%(output_array[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.test: output=[[[0.15423618 0.15855105 0.14283802 ... 0.16384062 0.14566855 0.16088895]\n",
      "  [0.1585408  0.16381977 0.16273938 ... 0.16582274 0.16399334 0.17201363]\n",
      "  [0.1498246  0.15605153 0.1372055  ... 0.16255465 0.13894618 0.15852246]\n",
      "  ...\n",
      "  [0.15657988 0.17567429 0.1628916  ... 0.17099947 0.16338056 0.17194912]\n",
      "  [0.15077394 0.15708219 0.14603648 ... 0.1604217  0.14346984 0.15656683]\n",
      "  [0.15156788 0.17715985 0.1542603  ... 0.17912021 0.15449512 0.17624675]]]\n"
     ]
    }
   ],
   "source": [
    "# output = (1, 512, 512)\n",
    "output = output_array[0][:,:,:,0] # A list with two images, get first one image and reshape it to 3 dimensions.\n",
    "recon = output_array[1][:,:,:,0]\n",
    "# image store in tuple structure.\n",
    "print('test.test: output=%s'%(output))\n",
    "np.ndim(output)\n",
    "np_output = np.array(output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting Output\n"
     ]
    }
   ],
   "source": [
    "# output_img = sitk.GetImageFromArray(output[0,:,:], isVector=True)\n",
    "\n",
    "print('Segmenting Output')\n",
    "\n",
    "# output_bin = threshold_mask(output, threshold_level)\n",
    "output2d = output[0,:,:]\n",
    "# output2d = recon[0,:,:]\n",
    "# print(output2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_level = 0.998\n",
    "mask = output2d[...] > threshold_level\n",
    "\n",
    "\n",
    "# Set all masked pixels to zero\n",
    "masked = img_data.copy()\n",
    "masked[mask] = 0\n",
    "# print(masked)\n",
    "# output_mask = sitk.GetImageFromArray(output_bin[0,:,:], isVector=True)\n",
    "#     output_img = np.reshape(output_img, [512, 512, 1])\n",
    "#     output_mask = np.reshape(output_mask, [512, 512, 1])\n",
    "\n",
    "# Display original and masked images side-by-side\n",
    "print('threshold_level=%f'%threshold_level)\n",
    "plt.figure()\n",
    "f, (ax0, ax1) = plt.subplots(1, 2)\n",
    "\n",
    "ax0.imshow(img_data)\n",
    "ax1.imshow(masked)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# cv2.imshow(\"Masked\",masked)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
